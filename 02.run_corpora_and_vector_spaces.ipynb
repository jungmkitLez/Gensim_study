{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T07:09:42.281801Z",
     "start_time": "2021-09-06T07:09:41.305756Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Corpora and Vector Spaces\n",
    "\n",
    "텍스트를 벡터 공간에 represent 하는 실습<br>\n",
    "그리고 corpus 스트리밍과 corpus가 저장소에 존재하는 다양한 포맷에 대해서<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T07:09:42.296782Z",
     "start_time": "2021-09-06T07:09:42.282806Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9개의 document로 이루어 진 corpus\n",
    "\n",
    "## From Strings to Vectors\n",
    "\n",
    "이번 document는 string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T07:09:42.312294Z",
     "start_time": "2021-09-06T07:09:42.297794Z"
    }
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Human machine interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\",\n",
    "    \"The generation of random binary unordered trees\",\n",
    "    \"The intersection graph of paths in trees\",\n",
    "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "    \"Graph minors A survey\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 9개의 documents로 이루어진 작은 corpus는 각각 한 문장으로 이루어져 있습니다.<br>\n",
    "\n",
    "먼저, documents를 토큰화 하고, 간단히 불용어와 corpus에서 한번나온 단어를 제거 하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T07:09:42.421583Z",
     "start_time": "2021-09-06T07:09:42.313796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'interface', 'computer'],\n",
      " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
      " ['eps', 'user', 'interface', 'system'],\n",
      " ['system', 'human', 'system', 'eps'],\n",
      " ['user', 'response', 'time'],\n",
      " ['trees'],\n",
      " ['graph', 'trees'],\n",
      " ['graph', 'minors', 'trees'],\n",
      " ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint  # pretty-printer\n",
    "from collections import defaultdict\n",
    "\n",
    "# 단어를 소문자로 바꾸고 불용어 처리\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [\n",
    "    [word for word in document.lower().split() if word not in stoplist]\n",
    "    for document in documents\n",
    "]\n",
    "\n",
    "# 한번만 나온 단어 제거\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [\n",
    "    [token for token in text if frequency[token] > 1]\n",
    "    for text in texts\n",
    "]\n",
    "\n",
    "pprint(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "documents를 처리하는 방식은 다양할 수 있습니다.\n",
    "\n",
    "documents를 처리하는 방식은 앱이나 언어 어디에 의존하냐에 따라 다양해 지는데, gensim은 특성 방식으로 제한을 두지 않았습니다.\n",
    "\n",
    "대신에, document는 표면적인게 아닌 document에서 추출된 특징으로 represent했습니다.\n",
    "\n",
    "어떻게 특징을 추출할지는 사용자에게 달려 있습니다.\n",
    "\n",
    "앞으로 일반적인 방식의 접근법을 볼겁니다(bag-of-words).\n",
    "\n",
    "그러나 언제나 다른 앱의 도메인에서는 다른 특징을 갖는다는 것을 기억해야 합니다.\n",
    "\n",
    "document를 변환시키기 위해서 bag-or-words를 사용할 것입니다.\n",
    "\n",
    "- Question: How many times does the word `system` appear in the document?\n",
    "- Answer: Once.\n",
    "\n",
    "위의 형식을 띄는 질-답 쌍입니다.\n",
    "\n",
    "질의는 integer형 id로 represent되고 id와 질의는 딕셔너리로 맵핑될 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T07:09:44.269867Z",
     "start_time": "2021-09-06T07:09:42.423936Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-06 16:09:44,204 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2021-09-06 16:09:44,204 : INFO : built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n",
      "2021-09-06 16:09:44,261 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\", 'datetime': '2021-09-06T16:09:44.205960', 'gensim': '4.0.1', 'python': '3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'created'}\n",
      "2021-09-06 16:09:44,261 : INFO : Dictionary lifecycle event {'fname_or_handle': './tmp/deerwester.dict', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2021-09-06T16:09:44.261589', 'gensim': '4.0.1', 'python': '3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'saving'}\n",
      "2021-09-06 16:09:44,263 : INFO : saved ./tmp/deerwester.dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('./tmp/deerwester.dict')  # store the dictionary, for future reference\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gensim 딕셔너리 클래스를 이용해서 corpus의 고유id와 모든 단어를 매칭시켰습니다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T07:09:44.285510Z",
     "start_time": "2021-09-06T07:09:44.271386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': 0, 'human': 1, 'interface': 2, 'response': 3, 'survey': 4, 'system': 5, 'time': 6, 'user': 7, 'eps': 8, 'trees': 9, 'graph': 10, 'minors': 11}\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T07:09:44.301165Z",
     "start_time": "2021-09-06T07:09:44.287042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리 전 : [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]\n",
      "처리 후: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "mylist = [[1,2,3,4],[5,6,7,8],[9,10,11,12]]\n",
    "\n",
    "print(f'처리 전 : {mylist}')\n",
    "\n",
    "mylist_merged = list(chain.from_iterable(mylist))\n",
    "\n",
    "print(f'처리 후: {mylist_merged}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토큰화된 documents를 벡터들로 변환시키기 위해서:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T07:09:44.316978Z",
     "start_time": "2021-09-06T07:09:44.302149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "new_doc = \"Human computer interaction\"\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    "print(new_vec)  # 딕셔너리에 없는 interaction 이란 단어는 무시되었다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doc2bow 함수는 단순히 모든 단어의 빈도수를 세고, 단어를 integer id로 변한하고, 희소 벡터 형태로 값을 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T07:09:44.332954Z",
     "start_time": "2021-09-06T07:09:44.319135Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-06 16:09:44,320 : INFO : storing corpus in Matrix Market format to ./tmp/deerwester.mm\n",
      "2021-09-06 16:09:44,321 : INFO : saving sparse matrix to ./tmp/deerwester.mm\n",
      "2021-09-06 16:09:44,322 : INFO : PROGRESS: saving document #0\n",
      "2021-09-06 16:09:44,323 : INFO : saved 9x12 matrix, density=25.926% (28/108)\n",
      "2021-09-06 16:09:44,324 : INFO : saving MmCorpus index to ./tmp/deerwester.mm.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1)], [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)], [(2, 1), (5, 1), (7, 1), (8, 1)], [(1, 1), (5, 2), (8, 1)], [(3, 1), (6, 1), (7, 1)], [(9, 1)], [(9, 1), (10, 1)], [(9, 1), (10, 1), (11, 1)], [(4, 1), (10, 1), (11, 1)]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpora.MmCorpus.serialize('./tmp/deerwester.mm', corpus)  # store to disk, for later use\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Streaming -- One Document at a Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T07:09:44.348562Z",
     "start_time": "2021-09-06T07:09:44.335460Z"
    }
   },
   "outputs": [],
   "source": [
    "from smart_open import open  # for transparently opening remote files\n",
    "\n",
    "\n",
    "class MyCorpus:\n",
    "    def __iter__(self):\n",
    "        for line in open('https://radimrehurek.com/mycorpus.txt'):\n",
    "            # 한 document에 한 줄씩, 공백일 기준으로 나뉘어 반환\n",
    "            yield dictionary.doc2bow(line.lower().split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim은 corpus가 iterable한 객체면 사용 가능합니다. like list,numpy,pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 유연함이 우리 corous 클래스가 디스크,네트워크,데이터베이스 등에서 직접 stream으로 documents를 가져올 수 있게 만듭니다.<br>\n",
    "Gensim에 있는 모델들은 모든 벡터가 한번에 메모리에 한번에 올라가도록 하지 않습니다. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 사용할 파일이 어떻게 생겼는지는 중요하지 않다.<br>\n",
    "단지 __iter__이 입력 형식하고 얼마나 잘 맞는지가 중요하다.(xml 파싱 같은)<br>\n",
    "입력데이터를 잘 파싱해서 각 document를 토큰들의 list로 만드는 것 뿐이다.<br>\n",
    "그리고 토큰들을 그들의 id와 매칭시켜 딕셔너리로 만들고 __iter__ 함수 내에서 희소벡터를 yield하면 된다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T07:09:44.363831Z",
     "start_time": "2021-09-06T07:09:44.349664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyCorpus object at 0x0000027E79CB2B20>\n"
     ]
    }
   ],
   "source": [
    "corpus_memory_friendly = MyCorpus()  # corpus를 메모리에 올리지 않습니다!!!!\n",
    "print(corpus_memory_friendly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T07:09:44.642663Z",
     "start_time": "2021-09-06T07:09:44.364842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1)]\n",
      "[(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n",
      "[(2, 1), (5, 1), (7, 1), (8, 1)]\n",
      "[(1, 1), (5, 2), (8, 1)]\n",
      "[(3, 1), (6, 1), (7, 1)]\n",
      "[(9, 1)]\n",
      "[(9, 1), (10, 1)]\n",
      "[(9, 1), (10, 1), (11, 1)]\n",
      "[(4, 1), (10, 1), (11, 1)]\n"
     ]
    }
   ],
   "source": [
    "for vector in corpus_memory_friendly:  # load one vector into memory at a time\n",
    "    print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딕셔너리도 파이썬 list처럼 메모리 절약적으로 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T07:09:44.953669Z",
     "start_time": "2021-09-06T07:09:44.643666Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-06 16:09:44,933 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2021-09-06 16:09:44,934 : INFO : built Dictionary(42 unique tokens: ['abc', 'applications', 'computer', 'for', 'human']...) from 9 documents (total 69 corpus positions)\n",
      "2021-09-06 16:09:44,935 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary(42 unique tokens: ['abc', 'applications', 'computer', 'for', 'human']...) from 9 documents (total 69 corpus positions)\", 'datetime': '2021-09-06T16:09:44.935894', 'gensim': '4.0.1', 'python': '3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...)\n"
     ]
    }
   ],
   "source": [
    "# collect statistics about all tokens\n",
    "dictionary = corpora.Dictionary(line.lower().split() for line in open('https://radimrehurek.com/mycorpus.txt'))\n",
    "# remove stop words and words that appear only once\n",
    "stop_ids = [\n",
    "    dictionary.token2id[stopword]\n",
    "    for stopword in stoplist\n",
    "    if stopword in dictionary.token2id\n",
    "]\n",
    "once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.items() if docfreq == 1]\n",
    "dictionary.filter_tokens(stop_ids + once_ids)  # remove stop words and words that appear only once\n",
    "dictionary.compactify()  # remove gaps in id sequence after words that were removed\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Formats\n",
    "\n",
    "Gensim에서는 corpus를 스트리밍하게 사용 할 수 있는 Matrix Market 같은 다양한 저장 포멧이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T07:09:44.969537Z",
     "start_time": "2021-09-06T07:09:44.955074Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-06 16:09:44,957 : INFO : storing corpus in Matrix Market format to ./tmp/corpus.mm\n",
      "2021-09-06 16:09:44,959 : INFO : saving sparse matrix to ./tmp/corpus.mm\n",
      "2021-09-06 16:09:44,959 : INFO : PROGRESS: saving document #0\n",
      "2021-09-06 16:09:44,960 : INFO : saved 2x2 matrix, density=25.000% (1/4)\n",
      "2021-09-06 16:09:44,961 : INFO : saving MmCorpus index to ./tmp/corpus.mm.index\n"
     ]
    }
   ],
   "source": [
    "corpus = [[(1, 0.5)], []]  # make one document empty, for the heck of it\n",
    "\n",
    "corpora.MmCorpus.serialize('./tmp/corpus.mm', corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joachim's SVMlight format <http://svmlight.joachims.org/><br>\n",
    "Blei's LDA-C format <http://www.cs.princeton.edu/~blei/lda-c/><br>\n",
    "GibbsLDA++ format <http://gibbslda.sourceforge.net/><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T07:09:44.984818Z",
     "start_time": "2021-09-06T07:09:44.970522Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-06 16:09:44,971 : INFO : converting corpus to SVMlight format: ./tmp/corpus.svmlight\n",
      "2021-09-06 16:09:44,975 : INFO : saving SvmLightCorpus index to ./tmp/corpus.svmlight.index\n",
      "2021-09-06 16:09:44,976 : INFO : no word id mapping provided; initializing from corpus\n",
      "2021-09-06 16:09:44,976 : INFO : storing corpus in Blei's LDA-C format into ./tmp/corpus.lda-c\n",
      "2021-09-06 16:09:44,977 : INFO : saving vocabulary of 2 words to ./tmp/corpus.lda-c.vocab\n",
      "2021-09-06 16:09:44,979 : INFO : saving BleiCorpus index to ./tmp/corpus.lda-c.index\n",
      "2021-09-06 16:09:44,980 : INFO : no word id mapping provided; initializing from corpus\n",
      "2021-09-06 16:09:44,980 : INFO : storing corpus in List-Of-Words format into ./tmp/corpus.low\n",
      "2021-09-06 16:09:44,981 : WARNING : List-of-words format can only save vectors with integer elements; 1 float entries were truncated to integer value\n",
      "2021-09-06 16:09:44,981 : INFO : saving LowCorpus index to ./tmp/corpus.low.index\n"
     ]
    }
   ],
   "source": [
    "corpora.SvmLightCorpus.serialize('./tmp/corpus.svmlight', corpus)\n",
    "corpora.BleiCorpus.serialize('./tmp/corpus.lda-c', corpus)\n",
    "corpora.LowCorpus.serialize('./tmp/corpus.low', corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반대로 Matrix Market 파일에서 corpus를 불러올 수도 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T07:09:45.000196Z",
     "start_time": "2021-09-06T07:09:44.985830Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-06 16:09:44,988 : INFO : loaded corpus index from ./tmp/corpus.mm.index\n",
      "2021-09-06 16:09:44,989 : INFO : initializing cython corpus reader from ./tmp/corpus.mm\n",
      "2021-09-06 16:09:44,991 : INFO : accepted corpus with 2 documents, 2 features, 1 non-zero entries\n"
     ]
    }
   ],
   "source": [
    "corpus = corpora.MmCorpus('./tmp/corpus.mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus stream 들은 바로 print 할 수없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T07:09:45.016335Z",
     "start_time": "2021-09-06T07:09:45.001555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MmCorpus(2 documents, 2 features, 1 non-zero entries)\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T07:09:45.032011Z",
     "start_time": "2021-09-06T07:09:45.017548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(1, 0.5)], []]\n"
     ]
    }
   ],
   "source": [
    "# one way of printing a corpus: load it entirely into memory\n",
    "print(list(corpus))  # calling list() will convert any sequence to a plain Python list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T07:09:45.047340Z",
     "start_time": "2021-09-06T07:09:45.033069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.5)]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# another way of doing it: print one document at a time, making use of the streaming interface\n",
    "for doc in corpus:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두번째 방법이 좀 더 메모리 친화적이고, 첫번째 방법은 간편합니다.<br>\n",
    "<br>\n",
    "Matrix Market document stream을 Blei's LDA-C 포맷으로 저장하려면 다음과 같이 합니다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T07:09:45.062786Z",
     "start_time": "2021-09-06T07:09:45.048518Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-06 16:09:45,049 : INFO : no word id mapping provided; initializing from corpus\n",
      "2021-09-06 16:09:45,050 : INFO : storing corpus in Blei's LDA-C format into ./tmp/corpus.lda-c\n",
      "2021-09-06 16:09:45,052 : INFO : saving vocabulary of 2 words to ./tmp/corpus.lda-c.vocab\n",
      "2021-09-06 16:09:45,053 : INFO : saving BleiCorpus index to ./tmp/corpus.lda-c.index\n"
     ]
    }
   ],
   "source": [
    "corpora.BleiCorpus.serialize('./tmp/corpus.lda-c', corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compatibility with NumPy and SciPy\n",
    "\n",
    "Gensim에는 또한 벡터를 numpy와 scipy로 변환할 수있는 기능을 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T07:09:45.078460Z",
     "start_time": "2021-09-06T07:09:45.063589Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "numpy_matrix = np.random.randint(10, size=[5, 2])  # random matrix as an example\n",
    "corpus = gensim.matutils.Dense2Corpus(numpy_matrix)\n",
    "number_of_corpus_features = 10 \n",
    "numpy_matrix = gensim.matutils.corpus2dense(corpus, num_terms=number_of_corpus_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `scipy.sparse` 매트릭스 들로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T07:09:45.094099Z",
     "start_time": "2021-09-06T07:09:45.079481Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "scipy_sparse_matrix = scipy.sparse.random(5, 2)  # random sparse matrix as example\n",
    "corpus = gensim.matutils.Sparse2Corpus(scipy_sparse_matrix)\n",
    "scipy_csc_matrix = gensim.matutils.corpus2csc(corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
